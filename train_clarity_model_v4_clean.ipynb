{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3NA8FI4aYMui",
    "outputId": "52006b4c-f208-45a1-f928-f2523fb46e1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers>=4.37 in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.37) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.37) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.37) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.37) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.37) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.37) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.37) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.37) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.37) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.37) (4.67.1)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.37) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.37) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.37) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.37) (2.5.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow, datasets\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 18.1.0\n",
      "    Uninstalling pyarrow-18.1.0:\n",
      "      Successfully uninstalled pyarrow-18.1.0\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 4.0.0\n",
      "    Uninstalling datasets-4.0.0:\n",
      "      Successfully uninstalled datasets-4.0.0\n",
      "Successfully installed datasets-4.4.1 pyarrow-22.0.0\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade \"transformers>=4.37\" datasets accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "u7Ngdov9gLIr"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    LukeTokenizer,\n",
    "    LukeForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mwDpcpLJgn6l",
    "outputId": "47bb24e7-31fc-4ab7-86c3-792e105e0607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (22.0.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.12.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.6\n"
     ]
    }
   ],
   "source": [
    "pip install evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0it4iF1BBRLr",
    "outputId": "35e605c9-5126-4be2-e23d-9d17b2a9cd58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (6.0.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2025.11.12)\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "4a3e8d0b9284454c84d76742ebe62235",
      "dcb8d1af98454101ad6903a3bb507fb5",
      "cbd463d432c342b98c9574cc889a0034",
      "3c77fd415f8440578de232d9c0c7407e",
      "2fa452481ff54b8383b71048c66a4c7a",
      "30cb86b2dfd6463e8c03490a5bac0a1c",
      "f9658e25f3b94daf83b913227683870d",
      "647069be1d8f401a87f79121bae3ded8",
      "036762747804463284bc6abc15f78b76",
      "9790d16f022b40b68080f8ae11b00511",
      "6954fe292b7c49819d794a60534c5a97",
      "0b952af424b34ee4971bc56096358099",
      "b1fa066b2d844fe6937ca429cfb973f0",
      "619de14382e04a80bbcce0cdc35b517b",
      "71d6d0fa061740908c40fe8d4cca5eff",
      "9bcd92dc9a3345f4a858559c3ea83379",
      "b31db684a6b3420495ecc3256e18118f",
      "89c85379d37948c3ab623bbbb23cc7e1",
      "887266f1f83c4011902cde924edabb2c",
      "8c85aa5440f842deb4aa34c8ec1337aa"
     ]
    },
    "id": "wsLUrOY5BBTC",
    "outputId": "8979fcc3-605d-4d3f-cfb8-11f83124f220"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3e8d0b9284454c84d76742ebe62235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299,
     "referenced_widgets": [
      "8e0a742e06a74624812d54f41b3fea4b",
      "749db336ca244b3b926f0861cb191a01",
      "969fde2f04ec4ac5a3181dbe35fafbd6",
      "8dc27e05537a4107ae8d4152a1379a91",
      "a6e13fb148b5457aac4f59d2885ad73f",
      "6b4e99308c9c495dae440cc50a286e59",
      "030318e42c644fbbaa297b335d854eb4",
      "4898f78176634653b1256318577d2fb3",
      "3b0e2f7f0aa04a71b15a085d556313ac",
      "e051154c3c2d454e9f4721578c258b0f",
      "a7a95651961e498ea27ef31daf017ca6",
      "d5852ecc16e74ff78249d2e81e1578cb",
      "c7a84c5f70674d37a326a5883574cdea",
      "960f55563c094bc6828f96263de7ed22",
      "9196a14afe484dbb8c34449aba29acfe",
      "308ee60d373b4c9ea08326d49f0ace82",
      "9719f583447948ac9f5bc5aa9f199479",
      "71cd2696af0d4e3793de7ed6709740dd",
      "f79191d1b7304e1083b3e2542e1d9ae0",
      "933c912d84024541bbfd205c35e5d91d",
      "38ac7a1777ca47d3b097199c893bc658",
      "48cd8083a22247ecaee6578e253ea080",
      "107da36443254854b5adb8b9cc392741",
      "6b93bbb1c5c741cca6bbe0986e5649f5",
      "5154e7bb7db54e1f9954f7d18487f1f9",
      "425f786b44524f7497b815838dd65312",
      "ab6c821723b14784808eedc2a5e4640c",
      "3aaac3a532e64ec4a90db73a45aa075c",
      "dc5180a874c04d3a9008bc922034db32",
      "a270903d757e4e5b9c12d3b508365639",
      "4d01d81132ea44659f930463ac5d3f5e",
      "963d344a9ed641ff980c2a9be4195194",
      "bfc2a53f00c0462aba2cd73d031d37f4",
      "b01339f538434216a9be8be189898d52",
      "df4f16c5761249c4979a5e602de8a2df",
      "7636c110ce664ec494f353b974317f45",
      "de10f6764a104ad98b3087d28cd15c77",
      "944c4798ef6e46b5b64a6c50d5d2df54",
      "376aeae26f2c4fe7b6184f01cba86f6b",
      "f9109624ff7649a5b9159f36f472deee",
      "561bc97065cf4ebaa927ad8732922720",
      "a7541ad8de814e378424635c34d22496",
      "93e666b1b25f44d18c0e2bf1898e3f8e",
      "39bf77757a7c4777b153c24f3bd1ca0a",
      "9b42782739aa482dbdaa518bccdeceac",
      "20f6927efad842a0b7851ad4189cca04",
      "eab5e9b3ac7041a5a005de0f4272c835",
      "09a9ef5b1ea44647895cd19b25f61d59",
      "0b61274af0f94eec922a4b83003c8528",
      "5fc8a9887c3d46339dd6149fa39bc643",
      "c437c55c95064b8b8b1b3cb7a8da8bed",
      "daf70712deb84556ad4ba63beb85dce8",
      "25d4634be3a647829155a25d78c51b39",
      "6eac6aa7ec084c2787f5eb87a8eb4cac",
      "a642654a5a164659b0a8f3af432456e2"
     ]
    },
    "id": "qaDVRFyggvn0",
    "outputId": "d1d880e4-b8d1-4810-fceb-ef4db703f9fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0a742e06a74624812d54f41b3fea4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5852ecc16e74ff78249d2e81e1578cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/3.90M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107da36443254854b5adb8b9cc392741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/259k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01339f538434216a9be8be189898d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b42782739aa482dbdaa518bccdeceac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"ailsntua/QEvasion\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "f310bc3bbda342799f1e591c04cd8fa2",
      "86694804d52b4a6490af65252ac62837",
      "1e9cf8e892be431790f6a9f51b234620",
      "62591cac6ec74c56bd2f117ecfa49c77",
      "d7011885935a475080f6ebd269d247c4",
      "2783adb7892e4194af78f0c623ee8c40",
      "6199c7bb97bf46aa8588db63079fd100",
      "1bec2eb3e7874dcba655c9eae89df614",
      "033c3481bc5c45f1b8884431fe819825",
      "8abc004c4d6d45ceaad6ab37029150b0",
      "3e0b0e7deef842368ee1a2c4547a1946",
      "576714453ed54b978ac90593b545f8bb",
      "6c7ac20d83ee488888aaf75dabf82359",
      "a29b43cfebb34e4f85b0f31948e61f61",
      "e07c54dfdfb04b968ba71e4f8d9074c5",
      "1c56bf6222ee45fda64d1794a206d86d",
      "3c0961c89d6041f892350fe4e1cd153e",
      "e225e3b0890c4bc8af4f73abed4e15f7",
      "0f90240b5fcb42e38c8689c8047f5da7",
      "a6855fb0f646402ea1eb00fdfc3d0415",
      "b1bd368444ee4fbdbc1c4b107ba7fc1e",
      "307b97ed13964c1a9ed5516b0639db9b"
     ]
    },
    "id": "B_u4MOcTBeiJ",
    "outputId": "d0fc6073-55fe-44b0-a2ee-280a42f756f7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f310bc3bbda342799f1e591c04cd8fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576714453ed54b978ac90593b545f8bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = ds.filter(lambda x: x[\"interview_question\"] is not None and x[\"interview_answer\"] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvP3zr8GBmtl",
    "outputId": "dc507a73-dfa5-4467-d504-24467b9e1bd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Claims ignorance': 0, 'Clarification': 1, 'Declining to answer': 2, 'Deflection': 3, 'Dodging': 4, 'Explicit': 5, 'General': 6, 'Implicit': 7, 'Partial/half-answer': 8}\n"
     ]
    }
   ],
   "source": [
    "evasion_labels = sorted(set(ds[\"train\"][\"evasion_label\"]))\n",
    "evasion2id = {c: i for i, c in enumerate(evasion_labels)}\n",
    "id2evasion = {i: c for c, i in evasion2id.items()}\n",
    "num_labels = len(evasion_labels)\n",
    "\n",
    "print(evasion2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YLy_2o3rBtnx",
    "outputId": "6a2f1a3b-2609-45cf-be5c-cedf49b58ced"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2930\n",
      "Valid size: 518\n",
      "HF test size (do NOT train on this): 308\n"
     ]
    }
   ],
   "source": [
    "train_valid = ds[\"train\"].train_test_split(test_size=0.15, seed=42)\n",
    "train_ds = train_valid[\"train\"]\n",
    "valid_ds = train_valid[\"test\"]\n",
    "\n",
    "print(\"Train size:\", len(train_ds))\n",
    "print(\"Valid size:\", len(valid_ds))\n",
    "print(\"HF test size (do NOT train on this):\", len(ds[\"test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327,
     "referenced_widgets": [
      "b39187cdf469456b8cf737785a8f44a2",
      "d3ad136307034a20a85e125533859878",
      "aa254ee741974beab6bae6758d1cd17b",
      "767d0930efac42cb8a3b43a9ef2ba649",
      "950d2d2311c448fbb943df903d687234",
      "b8acf9b7265c4e53ba6f923e4507d1df",
      "ac9237ef2f7848359d2cbe48d1fc1ba2",
      "e481792fda5b4b7aab47ea0f7849a128",
      "ef52c23b5eb84ec5bbdab20041785b5c",
      "d6dab740e09146809ee756aa2ad73975",
      "f5897691ae4140f284bb4bbe7361f0f4",
      "54ead8f65b9d49ad8e8e71468184c4e2",
      "6de2ffe957e5436089af31b60c73ae58",
      "76c1366f14a84bae83d51d26524779a5",
      "4eb0464a6d5f4d8b9afa24b67960a1c9",
      "ace4409d6c9244db84ce1d50bd39fdb8",
      "d8e14548b01541f6a2f74de7131f5a0b",
      "bf83da77c27a48bf8de2807c8f8eca91",
      "0da580bfda814d9a811673ca9e86ba30",
      "4a22da2a7dec4027b987fb2c3c0802c0",
      "0759173c3c054b4ba265a90ab2f0925d",
      "e48d202a6ca94e7db5681c944c0002c7",
      "6387d166ee1e4fe19dbdace6e8575ba6",
      "bdbdf15391404804a43c93790e2dc74a",
      "4985dea30c844ccabca775115220064d",
      "a91dff82f6d04dd29726755e7d809aec",
      "a27d540ef74743a68699c250b1cc19bf",
      "d536df96886c4642ab1f0d9fd6d48ea5",
      "91a7bbd61e8f4db6b20ec94dc3e9cecf",
      "c9440021e91f4ad983fad44ed87e3785",
      "ae7d2b588a524bb79e62ff4d7a5c87fc",
      "04c9db33f77b404ea3d92401dcd4e342",
      "116fad7375a34ecbb38095a045d54fa0",
      "39cd1308bfe24c549ee90f65c75705db",
      "bad0890428f740aa897a1e4bf0892e58",
      "f1512f87a04745b498669f5eafc486e6",
      "f6f0ed04e8d046e5bf69b3fcd5ab4d15",
      "21d05b8997374ce39f95828095911ce8",
      "f9bc97d7b2ef46149e7e2cf39cd5f84a",
      "e245e7bae27c4d7f9e4d8545f8988859",
      "4842c815e8394653a128911303085dbc",
      "950faec9676847eea36cb84f917a5677",
      "6008c88b511146a5ad6e963f8e3948b4",
      "6a4fbb1b53ad4da68006da76a5b6dcce",
      "a44b1fab78c344fc8d0b2591e7d50443",
      "f58b9a20c30b40dbb060454af0b2e633",
      "6c563ddc05ea4ca2b5fea999c24a2488",
      "20dcdfe7c30a40549cd89db02e475b27",
      "71c184bf8099412a9da042fc592a4386",
      "da428a82437f48eca500ea09cf98db09",
      "da93162dc7b74e97a0af1799439c329b",
      "d3794136acc043179d35a59c94c38d52",
      "f97b451939ae4ae0b14026375d909153",
      "e0aa6bee92964a12836f5dc17d23f66a",
      "ce8539e0485b4a26810ef7de18fe1f8f",
      "e9725e228ed941f99bcde7de5aa2aec9",
      "19b6959dc539440cbcf6e50820d3f5e2",
      "6dbc6053af524abb88941c7f78426433",
      "57c2938d2d454c54a49e76879bd675b6",
      "89dea09253604063958032b3f77aa82b",
      "8b0dfc5cda4a4e579d81b949acb74906",
      "17eaac0404d54169aab6f97ebc749b64",
      "4c7fb7edb05b4575baf5d58c62af7641",
      "142fdc84d50346c59e681df442cde302",
      "c1c67d0cccf6408db2130e70ea220d81",
      "40730819985c4d4fa1454f774d86392d",
      "37bbd7213cc64e1cb22c7df590c82034",
      "802df46d49a14cc8b3bc95bd32537aac",
      "28115976ac4941b78784ee44d619d806",
      "3cbc46978efc4807a7843645bf9f4beb",
      "702d9c494a3b4f2f841e4d0f12b4e400",
      "5d91db2625664b7aa904502cf552a027",
      "42e0c1f1f80e41eeb2bc9984e53f3005",
      "3f3d8a1bb038404b978f182547140736",
      "31ab9e046e284357b1e5cfac74556c59",
      "b56291ae10804fc0803c602b0fe0d51f",
      "8afd4d5d364449398130c9e5bd9485f7",
      "2c6010990e1e4d7db0e96661db7c4564",
      "eea8eca3faee4e17a7c32cbe2ad4a919",
      "def3acd005144449b8d0f2ab20407844",
      "405781a8cbaa431fb81d2fd7fa731ade",
      "be4495ce5247419ca906a80c873db013",
      "d63b02af3d8c40d594cfc6b7564722a9",
      "95c1d08976cb4973b58ecb72171c31bf",
      "9218dcd9d95748368a101a0cb0ae9eb0",
      "1278d53e7c5247dc916dc9087848c6a4",
      "16eab4fd7bf644db8033f5892cf6e30d",
      "a29ca45305a143168f1fa33ee4a61927"
     ]
    },
    "id": "aT1lHJlYCks5",
    "outputId": "7449de79-b5e6-438c-b6fd-8cabd0328a75"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39187cdf469456b8cf737785a8f44a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ead8f65b9d49ad8e8e71468184c4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6387d166ee1e4fe19dbdace6e8575ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39cd1308bfe24c549ee90f65c75705db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "entity_vocab.json:   0%|          | 0.00/15.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44b1fab78c344fc8d0b2591e7d50443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/33.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9725e228ed941f99bcde7de5aa2aec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37bbd7213cc64e1cb22c7df590c82034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/836 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6010990e1e4d7db0e96661db7c4564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.10G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LukeForSequenceClassification were not initialized from the model checkpoint at studio-ousia/luke-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import LukeTokenizer, LukeForSequenceClassification\n",
    "model_name = \"studio-ousia/luke-base\"\n",
    "\n",
    "tokenizer = LukeTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = LukeForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2evasion,\n",
    "    label2id=evasion2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WGL-Htw6DRUP"
   },
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    qs = [q or \"\" for q in batch[\"question\"]]\n",
    "    ans = [a or \"\" for a in batch[\"interview_answer\"]]\n",
    "\n",
    "    texts = [f\"Q: {q} [SEP] A: {a}\" for q, a in zip(qs, ans)]\n",
    "\n",
    "    enc = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,\n",
    "    )\n",
    "    enc[\"labels\"] = [evasion2id[label] for label in batch[\"evasion_label\"]]\n",
    "    return enc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "0d12daf7793e45629970c681769d5d05",
      "9624735c1d294708b80700b9ca269cf3",
      "c6a6d39a774f45dfa1042c8714463217",
      "ba473690807148e6b3b36bf1b24d6200",
      "c680008041bb4c6a8c49865494837bdf",
      "c76a51b4d03743f39ea28b3ec4bccfee",
      "cd070656ce7f4341812bf7d68ab495c0",
      "186fd317f3bc4263828c363fb8ab0a15",
      "9199bfafff0246e7ba52ec0aa70656fa",
      "a4a9a26785694328a57352410e695e50",
      "966e2ff577f246af82b6a0ed255a3bdd",
      "c9cc770db0c44ed0897a556ab8794281",
      "6baaafd146fc49969f2f49ed74a51f29",
      "d845a87186524d89bea4b418154d4b75",
      "766b2ee742274c418da996c039b29ec0",
      "969b33ea331043ebba5f6ad90c25e961",
      "d6fdadb7aa864697bb37db2be498e017",
      "13381d38865445b5bd2e329cd116a7d0",
      "576c2121e78846c09157b603f87aebf6",
      "9431abe174ff49198ebda1425a073e30",
      "8030a5432af84456b94b26dd3f8b18e4",
      "238ca18de59c4631b48967c882e26f07",
      "5e933d5cf53e4ea8853b9c82b9016b11",
      "92ea4b4b524143c79b37395205e26478",
      "f332cf07aaa44d358b180d4a771dbc48",
      "8accc7de44ad4d7e93635afc3fc8bb80",
      "c7487d20c1724cf4983230d0e648c10b",
      "4fa2d68b0e6146849cfe0df91bae9fb7",
      "0561b979cf424a26ad43d9c011a0104a",
      "5ebfe413ca06433eb190f0c3ecb97e2b",
      "fffd7593fa22462a9029051fd2f5fd5e",
      "c21fb024a9374681b87e00bccd1290ed",
      "57ad04bc2673405ca0ac9f7627ade0d8"
     ]
    },
    "id": "TpH5GrywDTTi",
    "outputId": "c5ec3631-704d-4b29-f0bc-c60b113018fc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d12daf7793e45629970c681769d5d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.10G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9cc770db0c44ed0897a556ab8794281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2930 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e933d5cf53e4ea8853b9c82b9016b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/518 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_encoded = train_ds.map(preprocess, batched=True)\n",
    "valid_encoded = valid_ds.map(preprocess, batched=True)\n",
    "\n",
    "cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "train_encoded = train_encoded.remove_columns([c for c in train_encoded.column_names if c not in cols])\n",
    "valid_encoded = valid_encoded.remove_columns([c for c in valid_encoded.column_names if c not in cols])\n",
    "\n",
    "train_encoded.set_format(\"torch\")\n",
    "valid_encoded.set_format(\"torch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aUnZfJ0hYPi9",
    "outputId": "5c0b63dd-387f-4826-b78c-3fbe8f46ec4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label counts: Counter({'Explicit': 908, 'Dodging': 585, 'Implicit': 398, 'Deflection': 336, 'General': 325, 'Declining to answer': 124, 'Claims ignorance': 105, 'Clarification': 78, 'Partial/half-answer': 71})\n",
      "Class weights: [1.53418072 2.06524327 1.29910464 0.47943147 0.27536577 0.17741077\n",
      " 0.49565839 0.40474617 2.26885881]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "label_list_train = train_ds[\"evasion_label\"]\n",
    "counts = Counter(label_list_train)\n",
    "print(\"Train label counts:\", counts)\n",
    "\n",
    "class_counts = np.array([counts[label] for label in evasion_labels], dtype=float)\n",
    "class_weights = 1.0 / class_counts\n",
    "class_weights = class_weights / class_weights.sum() * len(class_weights)\n",
    "\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "loss_fct = nn.CrossEntropyLoss(weight=class_weights_tensor.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "a4da514eaf9a44368f07662dfba6812e",
      "45cb450a316542398cff94933bb0b9d3",
      "103b30c0359c4f70afcde682f312a815",
      "e6ead0b4ab9b481db6c047dec1116a5a",
      "73188ff1434849efa538ce17de659880",
      "ec79674bfd8744c8bc07539d3f100699",
      "a453e81785d4459a9d10623512299681",
      "1d37f79075b24ce69c8621ad34e5c956",
      "867de6654a5e4867a2580c1ee4a61705",
      "93493418863440968c7c9eb45717e1a9",
      "9e06dd86ba524bd3a1f71fe8c418f355",
      "2c75880bd5734c17b1d02510687493ec",
      "2e9f921917454ebea02e186b40375b3b",
      "a4bc6d034adc4890a614bc77ed12590f",
      "84416642aa714bada87ad7ee101a1068",
      "828fc50e6ef04bae954cd2ee7f1e3e25",
      "bcd35abb0fac43999ae1a75cdd8d9ca9",
      "e7c782101e434a9db0c871bfe024fcf9",
      "b8b9473176174959a6e7018d92cf8ec7",
      "be662bef75fe437295577e36703f4db1",
      "5d275c50d6134edd9bab5fb138217829",
      "813ee6a57178431aa6ebbe1588805d8c"
     ]
    },
    "id": "2AZPFmMTDdPu",
    "outputId": "aaca2835-d072-4119-a4a3-890835fcc202"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4da514eaf9a44368f07662dfba6812e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c75880bd5734c17b1d02510687493ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"macro_f1\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "izl2Rt0HDixF",
    "outputId": "6d252c50-480d-4610-f933-19371e2b14ec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1468' max='1468' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1468/1468 02:51, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.327000</td>\n",
       "      <td>2.002756</td>\n",
       "      <td>0.403475</td>\n",
       "      <td>0.349451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.052300</td>\n",
       "      <td>1.898085</td>\n",
       "      <td>0.376448</td>\n",
       "      <td>0.384923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.697600</td>\n",
       "      <td>2.169678</td>\n",
       "      <td>0.388031</td>\n",
       "      <td>0.375109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.453300</td>\n",
       "      <td>2.218036</td>\n",
       "      <td>0.401544</td>\n",
       "      <td>0.378054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1468, training_loss=0.8725914760246589, metrics={'train_runtime': 172.0736, 'train_samples_per_second': 68.11, 'train_steps_per_second': 8.531, 'total_flos': 1928239098900480.0, 'train_loss': 0.8725914760246589, 'epoch': 4.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=0):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        # Ensure class_weights_tensor is on the same device as the model\n",
    "        loss = nn.CrossEntropyLoss(weight=class_weights_tensor.to(model.device))(logits, labels)\n",
    "        if return_outputs:\n",
    "            return loss, outputs\n",
    "        return loss\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./luke-qevasion\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=100,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    greater_is_better=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_encoded,\n",
    "    eval_dataset=valid_encoded,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "EyVzS45qFtXz"
   },
   "outputs": [],
   "source": [
    "test_ds = load_dataset(\"ailsntua/QEvasion\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "NbWen_qgSN-T",
    "outputId": "69ffae9c-e4a3-49dd-b47a-392163306cd8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dodging', 'General', 'Implicit', 'General', 'Partial/half-answer', 'Dodging', 'General', 'Implicit', 'General', 'General']\n",
      "Total predictions: 308\n"
     ]
    }
   ],
   "source": [
    "def preprocess_test(batch):\n",
    "    qs = [q or \"\" for q in batch[\"question\"]]\n",
    "    ans = [a or \"\" for a in batch[\"interview_answer\"]]\n",
    "    texts = [f\"Q: {q} [SEP] A: {a}\" for q, a in zip(qs, ans)]\n",
    "\n",
    "    enc = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,\n",
    "    )\n",
    "    return enc\n",
    "\n",
    "test_encoded = test_ds.map(preprocess_test, batched=True)\n",
    "test_encoded.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "\n",
    "pred_output = trainer.predict(test_encoded)\n",
    "logits = pred_output.predictions\n",
    "pred_ids = np.argmax(logits, axis=-1)\n",
    "\n",
    "pred_labels = [id2evasion[int(i)] for i in pred_ids]\n",
    "\n",
    "print(pred_labels[:10])\n",
    "print(\"Total predictions:\", len(pred_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "Dsa4tgBlTQV8",
    "outputId": "31c40d5b-3392-413b-c46b-0d580335b229"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "pred_output = trainer.predict(test_encoded)\n",
    "logits = pred_output.predictions\n",
    "pred_ids = np.argmax(logits, axis=-1)\n",
    "\n",
    "pred_labels = [id2evasion[int(i)] for i in pred_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iSIvqkxqTTiV",
    "outputId": "f10019f9-ff13-45ee-d88d-186b9a425a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines in prediction file: 308\n"
     ]
    }
   ],
   "source": [
    "with open(\"prediction\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for label in pred_labels:\n",
    "        f.write(str(label).strip() + \"\\n\")\n",
    "\n",
    "\n",
    "with open(\"prediction\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "print(\"Lines in prediction file:\", len(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "luY7qjhUTXgx",
    "outputId": "3a4427b1-6105-4f5b-bcb9-7e11195b85b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: prediction (deflated 88%)\n",
      "Archive:  submission.zip\n",
      "  Length      Date    Time    Name\n",
      "---------  ---------- -----   ----\n",
      "     3021  2025-12-09 20:27   prediction\n",
      "---------                     -------\n",
      "     3021                     1 file\n"
     ]
    }
   ],
   "source": [
    "!zip submission.zip prediction\n",
    "!unzip -l submission.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "OWPGEVt4TcoW",
    "outputId": "48ad6181-713f-4bc8-8f53-ab13116e7415"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_4428a534-889f-46b2-85a5-7d075394de2a\", \"submission.zip\", 543)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download(\"submission.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzOqzchlcs3X"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mxqThB1WcuTQ",
    "outputId": "d453dac8-5efc-47cb-afae-ff8fb6ae873c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clarity mapping: {'Ambivalent': 0, 'Clear Non-Reply': 1, 'Clear Reply': 2}\n"
     ]
    }
   ],
   "source": [
    "clarity_labels = sorted(set(ds[\"train\"][\"clarity_label\"]))\n",
    "clarity2id = {c: i for i, c in enumerate(clarity_labels)}\n",
    "id2clarity = {i: c for c, i in clarity2id.items()}\n",
    "num_clarity = len(clarity_labels)\n",
    "\n",
    "print(\"Clarity mapping:\", clarity2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9AAEdDDbeaRs",
    "outputId": "60953ff7-37ce-4b8b-841a-40c35d16d838"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2930\n",
      "Valid size: 518\n",
      "HF test size (not used for training): 308\n"
     ]
    }
   ],
   "source": [
    "train_valid = ds[\"train\"].train_test_split(test_size=0.15, seed=42)\n",
    "train_ds = train_valid[\"train\"]\n",
    "valid_ds = train_valid[\"test\"]\n",
    "\n",
    "print(\"Train size:\", len(train_ds))\n",
    "print(\"Valid size:\", len(valid_ds))\n",
    "print(\"HF test size (not used for training):\", len(ds[\"test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233,
     "referenced_widgets": [
      "633d3afdcf76441bbf161f3af2ec2be9",
      "37a94f1875294089bce51108c1a32032",
      "6171da7c0e594f52bf206541e797c726",
      "0fb13e9ecc3b44c5986c8649ef4c0708",
      "cded5cba341a41c8b61f3f8ec0f970d5",
      "66a5e524333c4d5998f5678711b3f499",
      "fa9dd3d02d6745ad859b91be5ad1bf30",
      "201d049e91064f6da5bb9dab49b2c821",
      "d9fda3a74f324356927dd3069170b78f",
      "d190616faff644a5ac705510232df01a",
      "58cf28cf73f044b1b7ae4346b8677959",
      "664f594f8728470794713de903b474b4",
      "8596e79658f540f7a83473fc21134817",
      "cde7c831d2864416acc9f4ad7d211c3d",
      "2cb6d00b12e64a0d927bc4cde72f07d0",
      "725596a54ae0419894255a146953a1fd",
      "553806b020b94bb5a96832e9ba750cc4",
      "92bd8e7832a74b9bbc10447e78d47f36",
      "f04e46d98dd24bbbb95a78fb4a7a8aa5",
      "f637bc02bcf9426090ac376d28fd0e04",
      "3c87da9b1b8442acb6e1f7b7e3357e9e",
      "e1f439cc33c44c51861e687c03cc035a",
      "028be659c5264ec0bbcda1471ae1b8e0",
      "5666bc82e5af428d8a3c9fce924c5593",
      "ca9a3036ea78426c9ee58ed95921cb38",
      "9be5862f236645faa8e59eea53861a79",
      "0978db0fb898456e8395df9f58bd0eff",
      "12aeb5a81cc244ab822bcb6f0e3220a8",
      "15c3848fec63417dbb8d7def5403c484",
      "7f790749df8b4e268ae045aa3a0f90a4",
      "a754f2ae177044d9a2cc3f114f351eb2",
      "ca53307d37c8489e9ce03d07c67ecbb5",
      "098fdb1d653144c4bbbc44e814679c5a",
      "2667103bf0b24762bc93ba6e6a557b2e",
      "7b6829ddd5ce4748975ffc972623a677",
      "acb95314d6ba4444af69ec709ac29e51",
      "389db2002a3c49d89c43b2274008a364",
      "42c4df4d245d4494a19405e41ded647b",
      "0ab0867e50b741de8b4849b0d611a5ee",
      "78029380792544fda3cdbb46b89be2bc",
      "9545c8fb98ac4408a196b7ff7ab39584",
      "996d23d90d864acf94a6ec700d7e3f2f",
      "43e3404d0daf4b90a3ffdaf9024a7391",
      "ade6e0851e874b569a79d00ade22c955"
     ]
    },
    "id": "oMlK3Y--edzx",
    "outputId": "46ec9be4-3f15-40e3-ac57-f37db7a6cb13"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633d3afdcf76441bbf161f3af2ec2be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664f594f8728470794713de903b474b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028be659c5264ec0bbcda1471ae1b8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2667103bf0b24762bc93ba6e6a557b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"microsoft/deberta-v3-base\"\n",
    "\n",
    "clarity_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "clarity_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_clarity,\n",
    "    id2label=id2clarity,\n",
    "    label2id=clarity2id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "6efc4961b7ed41929aa69ae07d231cfb",
      "4a0847ca1cde47edba0a12f74c5b8996",
      "d39a873ef0d94c21a3e5adb31f3e172f",
      "211bc3a09e474d54b255f84b7db1c76b",
      "48bf8cc5cf9d4e1f9112012d0bc91cb6",
      "bd71a3a4124145ea9c438f7dc8bbc408",
      "0d30ef5209d946079234858fa94c34f7",
      "99957da7fd4e4f9ba1e88d41ffa83af5",
      "0b3b6738afdf433289f8ddb2f9574011",
      "099ab3c08ab74ca6b4c7f067899e03aa",
      "b08c08941ad24dd4bdd6c8be919309e6",
      "790fab8fc1ad4ab49928aa9ded7da76a",
      "c997b21dc6c94145abfaf3557b6180cf",
      "53c056e963734f68bd95072ab7c89431",
      "e515881b6d9e4975b152ab9463c1a555",
      "aad943e708274659a92d2c968c9836d2",
      "380df0272d7a4a0bb7ce8721b1ee6fab",
      "1d02442e90ac47ee8456281db3192c77",
      "8ed5a46f77eb49b3a4291770f1729c95",
      "04027961b384407786eca5262b34c9b4",
      "4c928014ab1f4ba2850af4b0e3d8db1d",
      "eb592f9d01bf4644944d708260c96b29"
     ]
    },
    "id": "qrS2w6QOelLa",
    "outputId": "8a10da0d-8eb7-4490-8725-7a2381b492bf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6efc4961b7ed41929aa69ae07d231cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2930 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790fab8fc1ad4ab49928aa9ded7da76a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/518 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_text(q, a, ev_label):\n",
    "    # You can tweak wording if you like\n",
    "    return f\"Evasion: {ev_label}. Q: {q} [SEP] A: {a}\"\n",
    "\n",
    "def preprocess_clarity_train(batch):\n",
    "    qs   = [q or \"\" for q in batch[\"question\"]]\n",
    "    ans  = [a or \"\" for a in batch[\"interview_answer\"]]\n",
    "    evas = [e or \"\" for e in batch[\"evasion_label\"]]   # GOLD evasion\n",
    "\n",
    "    texts = [make_text(q, a, e) for q, a, e in zip(qs, ans, evas)]\n",
    "\n",
    "    enc = clarity_tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,\n",
    "    )\n",
    "    enc[\"labels\"] = [clarity2id[l] for l in batch[\"clarity_label\"]]\n",
    "    return enc\n",
    "\n",
    "train_encoded = train_ds.map(preprocess_clarity_train, batched=True)\n",
    "valid_encoded = valid_ds.map(preprocess_clarity_train, batched=True)\n",
    "\n",
    "cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "train_encoded = train_encoded.remove_columns(\n",
    "    [c for c in train_encoded.column_names if c not in cols]\n",
    ")\n",
    "valid_encoded = valid_encoded.remove_columns(\n",
    "    [c for c in valid_encoded.column_names if c not in cols]\n",
    ")\n",
    "\n",
    "train_encoded.set_format(\"torch\")\n",
    "valid_encoded.set_format(\"torch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6OLB3mIxeuJG",
    "outputId": "9220b416-d8df-4244-c746-fd6b567c0619"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train clarity counts: Counter({'Ambivalent': 1715, 'Clear Reply': 908, 'Clear Non-Reply': 307})\n",
      "Clarity class weights: [0.35397872 1.97743813 0.66858315]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "clr_counts = Counter(train_ds[\"clarity_label\"])\n",
    "print(\"Train clarity counts:\", clr_counts)\n",
    "\n",
    "class_counts = np.array([clr_counts[l] for l in clarity_labels], dtype=float)\n",
    "class_weights = 1.0 / class_counts\n",
    "class_weights = class_weights / class_weights.sum() * len(class_weights)\n",
    "class_weights_t = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "print(\"Clarity class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "9eQ4MlhPex_r",
    "outputId": "2b42c327-a2c2-4561-a316-50948d776460"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='1101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  56/1101 00:27 < 08:54, 1.96 it/s, Epoch 0.15/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-340040964.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mclarity_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclarity_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2326\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2677\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2678\u001b[0m                         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2679\u001b[0;31m                         \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2680\u001b[0m                     ):\n\u001b[1;32m   2681\u001b[0m                         \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"macro_f1\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
    "    }\n",
    "\n",
    "class WeightedClarityTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=0):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss = nn.CrossEntropyLoss(weight=class_weights_t.to(model.device))(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./deberta-clarity-with-evasion\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=100,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    greater_is_better=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "clarity_trainer = WeightedClarityTrainer(\n",
    "    model=clarity_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_encoded,\n",
    "    eval_dataset=valid_encoded,\n",
    "    processing_class=clarity_tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "clarity_trainer.train()\n",
    "print(\"Validation:\", clarity_trainer.evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "271b772bc5704e058069bb24b8be2de4",
      "eec92c2188734a2ca03ec01b7ff6fad1",
      "e9e8b09867c047f3a4c066e765e6519c",
      "e56ee1a87b104e1493b86d223b8666cd",
      "12f12e925d944771b1e60f772eae31cd",
      "1624e77f38c649f5a4dc01b5af106af4",
      "08a39ed7d9024dcc879aef22f32a8d02",
      "edb31092975d4fafabacbf373ba147a4",
      "31a32e87eef14511855503d37fd829d3",
      "5710b16348f54ffba8ab10f225fdcb35",
      "e6e089623b454f83bb70dcfc529e97eb"
     ]
    },
    "id": "aG8JWoRhiEWD",
    "outputId": "dc8c1b9a-de8c-4043-ac11-5f47d256f991"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271b772bc5704e058069bb24b8be2de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dodging', 'General', 'Implicit', 'General', 'Explicit', 'Implicit', 'Implicit', 'Implicit', 'General', 'Implicit']\n",
      "Total evasion preds: 308\n"
     ]
    }
   ],
   "source": [
    "test_ds = ds[\"test\"]\n",
    "\n",
    "def preprocess_evasion_test(batch):\n",
    "    qs  = [q or \"\" for q in batch[\"question\"]]\n",
    "    ans = [a or \"\" for a in batch[\"interview_answer\"]]\n",
    "    texts = [f\"Q: {q} [SEP] A: {a}\" for q, a in zip(qs, ans)]\n",
    "\n",
    "    enc = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,\n",
    "    )\n",
    "    return enc\n",
    "\n",
    "evasion_test_encoded = test_ds.map(preprocess_evasion_test, batched=True)\n",
    "evasion_test_encoded.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "\n",
    "# LUKE predictions\n",
    "evasion_pred_output = trainer.predict(evasion_test_encoded)\n",
    "evasion_logits = evasion_pred_output.predictions\n",
    "evasion_pred_ids = np.argmax(evasion_logits, axis=-1)\n",
    "evasion_pred_labels = [id2evasion[int(i)] for i in evasion_pred_ids]\n",
    "\n",
    "print(evasion_pred_labels[:10])\n",
    "print(\"Total evasion preds:\", len(evasion_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "8558dc3bbeb04df085b1d0ceb10888bd",
      "990d24fe8204413c889083cefe5b244f",
      "52a449aa6b694a398772627805726bc7",
      "41bedfd54c7c49518a2907be26e21b12",
      "a787a9bc18b94870915a0110c8733fea",
      "54bc3fd2fa8e42a3a9035d8b255f4033",
      "11aa940e494d4a179bc1ed18802e3da7",
      "95b441e68a2d4c8c9821bd39ad7fb983",
      "eae1c03353f44264b99c10fcbbd04c0f",
      "da8c0b239ca144ce841ea97beb72e69e",
      "a3e30e883de94d0a8eb00ed4bb41b544",
      "67ab8827e59742258fe498a5b8563103",
      "11785b9f1d0c49c49ab800d57a0f6ec2",
      "faa1e750d9cd40bbb02d2c63cdd367dc",
      "5199f213be40472eb68a4e2be1674d68",
      "fb039d1bf7ef4449b465f21d408cdc7e",
      "1de3e1d54b9c4707bbe2ee61eb7f5dbb",
      "5bc4424ad8e3426a997c849ec321945f",
      "46c814bcac474123ae03fc4908bbc420",
      "fb79abca180e4fea9813f71f2b5e3ba0",
      "807fadc34cdb42f692ac13cfc8ce0f37",
      "fdb9873e87a44fcb80eaaa14ddc31c00"
     ]
    },
    "id": "m6dHmdP3jFLP",
    "outputId": "cbbbbbcf-880b-4293-9790-58d09aa5e01e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8558dc3bbeb04df085b1d0ceb10888bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ab8827e59742258fe498a5b8563103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/308 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "assert len(test_ds) == len(evasion_pred_labels)\n",
    "test_with_evasion = test_ds.add_column(\"pred_evasion_label\", evasion_pred_labels)\n",
    "\n",
    "def preprocess_clarity_test(batch):\n",
    "    qs   = [q or \"\" for q in batch[\"question\"]]\n",
    "    ans  = [a or \"\" for a in batch[\"interview_answer\"]]\n",
    "    evas = [e or \"\" for e in batch[\"pred_evasion_label\"]]\n",
    "\n",
    "    texts = [make_text(q, a, e) for q, a, e in zip(qs, ans, evas)]\n",
    "\n",
    "    enc = clarity_tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,\n",
    "    )\n",
    "    return enc\n",
    "\n",
    "test_encoded_clarity = test_with_evasion.map(preprocess_clarity_test, batched=True)\n",
    "test_encoded_clarity.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "dnZPas3NjOLf",
    "outputId": "49a29f2a-5717-45ee-b439-cd03f0ff1b50"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ambivalent', 'Ambivalent', 'Ambivalent', 'Ambivalent', 'Clear Reply', 'Ambivalent', 'Ambivalent', 'Ambivalent', 'Ambivalent', 'Ambivalent']\n",
      "Total clarity preds: 308\n",
      "Lines in prediction file: 308\n",
      "updating: prediction (deflated 95%)\n",
      "Archive:  submission.zip\n",
      "  Length      Date    Time    Name\n",
      "---------  ---------- -----   ----\n",
      "     3623  2025-12-09 19:18   prediction\n",
      "---------                     -------\n",
      "     3623                     1 file\n"
     ]
    }
   ],
   "source": [
    "clarity_pred_output = clarity_trainer.predict(test_encoded_clarity)\n",
    "clarity_logits = clarity_pred_output.predictions\n",
    "clarity_pred_ids = np.argmax(clarity_logits, axis=-1)\n",
    "clarity_pred_labels = [id2clarity[int(i)] for i in clarity_pred_ids]\n",
    "\n",
    "print(clarity_pred_labels[:10])\n",
    "print(\"Total clarity preds:\", len(clarity_pred_labels)\n",
    "with open(\"prediction\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for label in clarity_pred_labels:\n",
    "        f.write(str(label).strip() + \"\\n\")\n",
    "\n",
    "with open(\"prediction\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "print(\"Lines in prediction file:\", len(lines))\n",
    "\n",
    "!zip submission.zip prediction\n",
    "!unzip -l submission.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "v4_1gcLfjTod",
    "outputId": "97a74b42-f47c-45ac-a14d-38735e0c4dcb"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_210304eb-a590-4b45-b5fe-1414db9da761\", \"submission.zip\", 357)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download(\"submission.zip\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
